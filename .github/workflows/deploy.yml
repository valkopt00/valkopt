name: Update News JSON

on:
  schedule:
    - cron: "*/15 * * * *"  # Runs every 15 minutes
  workflow_dispatch:

jobs:
  update-json-data:
    name: Generate and Update Data Branch
    runs-on: ubuntu-latest

    steps:
      # ✅ OPTIMIZATION 1: Direct checkout of data branch (if exists) or main
      - name: Checkout data branch if exists
        id: checkout_data
        continue-on-error: true
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          ref: data
          token: ${{ secrets.GITHUB_TOKEN }}

      # ✅ OPTIMIZATION 2: Fallback to main if data doesn't exist
      - name: Checkout main if data failed
        if: steps.checkout_data.outcome == 'failure'
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          ref: main
          token: ${{ secrets.GITHUB_TOKEN }}

      # ✅ OPTIMIZATION 3: Fetch main branch for script extraction
      - name: Fetch main branch for scripts
        if: steps.checkout_data.outcome == 'success'
        run: |
          echo "We're on data branch, fetching main for scripts"
          git fetch origin main

      # ✅ OPTIMIZATION 4: Setup data branch only if necessary
      - name: Create data branch if doesn't exist
        if: steps.checkout_data.outcome == 'failure'
        run: |
          echo "Data branch doesn't exist - creating orphan branch"
          git checkout --orphan data
          git reset --hard
          mkdir -p articles public
          
          # Create empty original_categories.json file
          echo '{"categories": {}, "articles": {}}' > articles/original_categories.json

      # ✅ OPTIMIZATION 5: Only create folders if already on data
      - name: Prepare folder structure
        if: steps.checkout_data.outcome == 'success'
        run: |
          echo "✅ Already on data branch"
          mkdir -p articles public
          
          # Create empty original_categories.json file if it doesn't exist
          if [ ! -f "articles/original_categories.json" ]; then
            echo '{"categories": {}, "articles": {}}' > articles/original_categories.json
          fi

      # ✅ OPTIMIZATION 6: Setup pip cache
      - name: Setup pip cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # ✅ OPTIMIZATION 7: Setup Python with automatic cache
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      # ✅ OPTIMIZATION 8: Extract scripts from main branch
      - name: Extract scripts and requirements from main branch
        run: |
          mkdir -p temp-scripts/scripts/exporters
          
          # Use origin/main reference
          git show origin/main:requirements.txt > temp-scripts/requirements.txt
          git show origin/main:scripts/RSS_API.py > temp-scripts/scripts/RSS_API.py
          git show origin/main:scripts/__init__.py > temp-scripts/scripts/__init__.py
          git show origin/main:scripts/mappings.py > temp-scripts/scripts/mappings.py
          git show origin/main:scripts/remove_articles.py > temp-scripts/scripts/remove_articles.py
          git show origin/main:scripts/reset_counts_with_backup.py > temp-scripts/scripts/reset_counts_with_backup.py
          git show origin/main:scripts/remove_duplicates.py > temp-scripts/scripts/remove_duplicates.py
          git show origin/main:scripts/exporters/export_original_categories.py > temp-scripts/scripts/exporters/export_original_categories.py

      # ✅ OPTIMIZATION 9: Install dependencies with cache
      - name: Install dependencies
        run: |
          # Install with cache (cache already avoids unnecessary reinstallations)
          pip install -r temp-scripts/requirements.txt

      - name: Run JSON update script
        run: |
          export PYTHONPATH=$(pwd)/temp-scripts
          python temp-scripts/scripts/RSS_API.py

      # ✅ OPTIMIZATION 10: Optimized HTML file copying
      - name: Ensure public folder and copy JSON files
        run: |
          mkdir -p public
          # Copy only essential JSON files
          cp articles/articles.json public/
          cp articles/articles_search.json public/
          cp articles/original_categories.json public/
          
          # Optimized copying of static HTML files (batch verification)
          for file in "politica_de_privacidade.html" "termos_de_utilizacao.html" "contacto.html" "app-ads.txt"; do
            if git cat-file -e origin/main:public/$file 2>/dev/null; then
              git show origin/main:public/$file > public/$file
            fi
          done

      - name: Verify generated files
        run: |
          echo "📁 Files in articles folder:"
          ls -la articles/
          echo ""
          echo "📁 Files in public folder:"
          ls -la public/
          echo ""
          cd public
          if [ -f "articles.json" ]; then
            size=$(stat -c%s "articles.json")
            echo "   ✅ articles.json: $(numfmt --to=iec $size) (all news)"
          else
            echo "   ❌ articles.json was NOT created"
          fi
          
          if [ -f "articles_search.json" ]; then
            size=$(stat -c%s "articles_search.json")
            echo "   ✅ articles_search.json: $(numfmt --to=iec $size) (search data)"
          else
            echo "   ❌ articles_search.json was NOT created"
          fi
          
          if [ -f "original_categories.json" ]; then
            size=$(stat -c%s "original_categories.json")
            echo "   ✅ original_categories.json: $(numfmt --to=iec $size) (mapping)"
          else
            echo "   ❌ original_categories.json was NOT created"
          fi

      - name: Create informative README
        run: |
          echo "# Data Branch - Simplified JSON System" > README.md
          echo "Automatically updated at: $(date '+%Y-%m-%d %H:%M:%S')" >> README.md
          echo "" >> README.md
          echo "## 🎯 Simplified architecture:" >> README.md
          echo "Only **3 essential JSON files**, automatically compressed by Netlify (~65% reduction):" >> README.md
          echo "" >> README.md
          echo "### 📱 For main app:" >> README.md
          echo "- **articles.json** - All categories and articles (single file)" >> README.md
          echo "" >> README.md
          echo "### 🔍 For search functionality:" >> README.md  
          echo "- **articles_search.json** - Normalized data for search" >> README.md
          echo "" >> README.md
          echo "### 🗂️ For category mapping:" >> README.md
          echo "- **original_categories.json** - Original category mapping" >> README.md
          echo "" >> README.md
          echo "## ⚡ Expected performance:" >> README.md
          cd public
          if [ -f "articles.json" ]; then
            size=$(stat -c%s "articles.json")
            compressed_size=$((size * 35 / 100))
            echo "- **Initial loading**: ~$(numfmt --to=iec $compressed_size) (2-4 seconds)" >> ../README.md
            echo "- **All categories**: Available immediately after loading" >> ../README.md
            echo "- **Zero timing issues**: No dependencies between files" >> ../README.md
          fi

      # ✅ OPTIMIZATION 11: Optimized commit (more efficient verification)
      - name: Commit and Push to data branch
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          
          # Optimized change verification
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Automatic JSON files update - $(date '+%Y-%m-%d %H:%M:%S')"
            git push origin data --force
          else
            echo "No changes to commit"
          fi